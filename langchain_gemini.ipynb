{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ce610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m venv venv\n",
    "# source venv/Scripts/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c85aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "python-jose 3.4.0 requires pyasn1<0.5.0,>=0.4.1, but you have pyasn1 0.6.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install langchain google-generativeai python-dotenv langchain_community langchain-google-genai faiss-cpu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67109732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #trabajar arhivoc de texto\n",
    "from dotenv import load_dotenv #\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load .env\n",
    "load_dotenv()\n",
    "\n",
    "#Configurar el modelo Gemini\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    google_api_key=os.getenv(\"GENAI_API_KEY\"),\n",
    "    temperature=0.7 #Creatividad del modelo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "335d5750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo Gemini 2.0 Flash es una versión optimizada para la velocidad y la eficiencia de los modelos Gemini. Por lo tanto, los principales beneficios de usar Gemini 2.0 Flash son:\n",
      "\n",
      "**1. Velocidad:**\n",
      "\n",
      "*   **Respuestas más rápidas:**  Esta es la principal ventaja. Gemini 2.0 Flash está diseñado para entregar resultados de manera significativamente más rápida que otros modelos Gemini (como Gemini 1.5 Pro). Esto es crucial para aplicaciones donde la latencia es importante, como chatbots en tiempo real, asistentes virtuales o herramientas de búsqueda interactivas.\n",
      "\n",
      "**2. Eficiencia de costos:**\n",
      "\n",
      "*   **Menor costo por token:** Debido a que utiliza menos recursos computacionales para generar respuestas, Gemini 2.0 Flash generalmente ofrece un costo por token más bajo en comparación con modelos más grandes. Esto es especialmente beneficioso para aplicaciones con un alto volumen de solicitudes.\n",
      "\n",
      "**3. Escalabilidad:**\n",
      "\n",
      "*   **Mayor capacidad de respuesta:** La velocidad y la eficiencia de costos se combinan para permitir una mayor escalabilidad. Puedes manejar un mayor volumen de solicitudes simultáneamente con la misma infraestructura o con costos reducidos.\n",
      "\n",
      "**4. Ideal para tareas específicas:**\n",
      "\n",
      "*   **Casos de uso enfocados:** Gemini 2.0 Flash está optimizado para tareas que no requieren la máxima sofisticación o comprensión profunda del lenguaje, pero que se benefician enormemente de la velocidad.  Ejemplos:\n",
      "    *   **Generación de texto conciso:**  Crear resúmenes breves, descripciones de productos o titulares.\n",
      "    *   **Traducción rápida:**  Traducir frases o párrafos cortos.\n",
      "    *   **Chatbots básicos:**  Manejar preguntas frecuentes o proporcionar información básica.\n",
      "    *   **Extracción de información:**  Identificar rápidamente entidades o palabras clave relevantes en un texto.\n",
      "    *   **Generación de código simple:** Crear fragmentos de código básicos o completar líneas de código.\n",
      "\n",
      "**En resumen, Gemini 2.0 Flash es la mejor opción cuando necesitas:**\n",
      "\n",
      "*   **Velocidad:**  Respuestas rápidas y baja latencia.\n",
      "*   **Costo:**  Una solución más económica.\n",
      "*   **Escalabilidad:**  Manejar un alto volumen de solicitudes.\n",
      "*   **Tareas específicas:**  Casos de uso que no requieran la máxima complejidad del lenguaje.\n",
      "\n",
      "**Consideraciones importantes:**\n",
      "\n",
      "*   **Compromiso en la calidad:**  La velocidad y la eficiencia a menudo implican un compromiso en la calidad de la respuesta.  Para tareas que requieren una comprensión profunda, razonamiento complejo o creatividad, un modelo más grande como Gemini 1.5 Pro podría ser más adecuado.\n",
      "*   **Evaluación:**  Es importante evaluar cuidadosamente Gemini 2.0 Flash en tu caso de uso específico para asegurarte de que cumple con tus requisitos de precisión y calidad.\n",
      "\n",
      "En definitiva, Gemini 2.0 Flash es una herramienta valiosa para desarrolladores que buscan una solución rápida, eficiente y rentable para una variedad de tareas de procesamiento del lenguaje natural.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo basico de chat\n",
    "response = llm.invoke(\"¿Cuales son los principales beneficios de usar el modelo gemini-2.0-flash-exp?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13262ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
